{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byline Similarities of names using [jellyfish](https://github.com/jamesturk/jellyfish)\n",
    "\n",
    "Bylines were extracted from the the last paragraph of each letter. This was done here [Extract bylines from raw letters](/notebooks/extract_letter_bylines.ipynb) where attempts to identify the different sections of byline including name, occupation and location done. This notebook is thus concerned with associating–despite errors in the OCR process–the named identities and number of letters they sent to the editor.\n",
    "\n",
    "Unlike semantic based algorithms such as the one provided by the spaCy nlp library (see [attempt Byline Similarities of names using spaCy](/notebooks/cluster_similar_reader_names_spacy.ipynb)), using jaro distance, one of similarity algorithms provided by jellyfish package performed much better overall and was thus employed in the research.\n",
    "\n",
    "In order maximise the results, `cleanup_name` function ensure noise characters such and other non-alphabeticals were removed altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanup_name(_input):\n",
    "    output = ireader_name = re.sub(r'[^A-Za-z0-9 ]+', '', _input) # strip dots\n",
    "    output = re.sub(r\"\\b[a-zA-Z0-9]\\b\", \"\", output) # remove single letter words\n",
    "    output = re.sub(' +', ' ', output) # remove successive spaces\n",
    "    output = output.strip() # remove leading and trailing spaces\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step helped to make similarities possible where otherwise would not have been established due to the state of the OCR errors. For example in the case below, two byline identities “HM Mwafusi” and “A H..M. Mwafusi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Similarity before clean-up: 0.8388888888888889\n",
      "    Similarity after clean-up: 1.0\n"
     ]
    }
   ],
   "source": [
    "import jellyfish\n",
    "\n",
    "id1 = 'HM Mwafusi'\n",
    "id2 = 'A H..M. Mwafusi'\n",
    "ratio = jellyfish.jaro_distance(id1, id2)\n",
    "print(f\"{'Similarity before clean-up:':>30} {ratio}\")\n",
    "\n",
    "id1 = cleanup_name(id1)\n",
    "id2 = cleanup_name(id2)\n",
    "ratio = jellyfish.jaro_distance(id1, id2)\n",
    "print(f\"{'Similarity after clean-up:':>30} {ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating similarities\n",
    "\n",
    "Two key parameters were used in the determinations. The `min_length` was used to limit valid words and ratio was set to `0.84` where results were reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903250003 | 903250004 |   the resovmed eters | athe resovmed aaters | 0.912 | 1978-01-03\n",
      "903350083 | 905881736 | Tappeal to the Government to do | appeal to the Governme | 0.903 | 1978-12-02\n",
      "903360087 | 903360092 | As far as Gema is concerned we | As far as Gema is concerned we | 1.000 | 1978-01-17\n",
      "903380103 | 904731083 |          FpA Apollos |           FM Apollos | 0.869 | 1978-06-28\n",
      "903400115 | 903880495 |      Wilfred Waititu |    Woailfred Waititu | 0.861 | 1978-03-18\n",
      "903400115 | 903910518 |      Wilfred Waititu |      Wilfred Waititu | 1.000 | 1978-03-22\n",
      "903400115 | 904200728 |      Wilfred Waititu |      Wilfred Waititu | 1.000 | 1978-04-26\n",
      "903440144 | 904731083 |            FM Appoll |           FM Apollos | 0.896 | 1978-06-28\n",
      "903440145 | 903480165 |  ion Mrs KeliNairobi | Ring Mrs KeliNairobi | 0.949 | 1978-01-31\n",
      "903470162 | 903710348 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-02-27\n",
      "903470162 | 903750382 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-03-03\n",
      "903470162 | 903980582 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-03-31\n",
      "903470162 | 904881169 |       Jimmy Mohammed |      Jinimy Mohammed | 0.932 | 1978-07-14\n",
      "903490171 | 903620265 |  Tokyo Charles Waldi |       oy Charles Wal | 0.912 | 1978-02-16\n",
      "903550213 | 903940550 |        Thande Bakana |         hande Bakano | 0.921 | 1978-03-27\n",
      "903590244 | 904060630 | METROPOLITAN COLLEGE DEPTWD | METROPOLITAN COLLEGE DBI | 0.910 | 1978-04-10\n",
      "903630280 | 905241334 |          my Mahammed |          my Mohammed | 0.906 | 1978-09-19\n",
      "903690327 | 903950562 |   Frustrated citizen |           Frustrated | 0.852 | 1978-03-28\n",
      "903690329 | 905701626 |              Mombasa |              Mombasa | 1.000 | 1978-11-11\n",
      "903690330 | 903700343 |     Bitindwa Sibocha |     Bitindwa Sibocho | 0.958 | 1978-02-25\n",
      "903690330 | 905231328 |     Bitindwa Sibocha |     Birindwa Sibocha | 0.958 | 1978-09-18\n",
      "903700334 | 905961789 |           ee Nairobi |              Nairobi | 0.900 | 1978-12-12\n",
      "903700337 | 904731083 |           EM Apolios |           FM Apollos | 0.867 | 1978-06-28\n",
      "903740370 | 903740377 |  In his classic work |  In his classic work | 1.000 | 1978-03-02\n",
      "903760393 | 905721640 |                Kenya |              Kenyans | 0.905 | 1978-11-14\n",
      "903840452 | 903860467 |  Uhuru Highway POBox | Uhuru Highway POBox 43617 Na | 0.893 | 1978-03-16\n",
      "903910521 | 905151278 |         Daudi Luvusi |         Doudi Luvusi | 0.944 | 1978-09-08\n",
      "903910521 | 905281356 |         Daudi Luvusi |         Daudi Lavesi | 0.889 | 1978-09-23\n",
      "903930533 | 905261343 |          Perhaps the |          Perhaps the | 1.000 | 1978-09-21\n",
      "904230751 | 904230753 |  Evans Ernest Luseno |  Evans Ernest Luseno | 1.000 | 1978-04-29\n",
      "904230751 | 905631575 |  Evans Ernest Luseno |    Evans Ernest send | 0.928 | 1978-11-03\n",
      "904330822 | 904330823 | will be the least result | will be the least result | 1.000 | 1978-05-11\n",
      "904350842 | 904350844 |           he tiidest |           he tiidest | 1.000 | 1978-05-12\n",
      "904390871 | 904390872 | The meeting will be informal and willcommence punctual | The meeting will be informal and willcommence punctual | 1.000 | 1978-05-18\n",
      "904390873 | 904390874 | sesamin Baorcld Memse | sesamin Baorcld Memse | 1.000 | 1978-05-18\n",
      "904420892 | 904420895 |        Sylvia Fraser |        Sylvia Fraser | 1.000 | 1978-05-22\n",
      "904611014 | 904951202 |               PO Box |               PO Box | 1.000 | 1978-07-22\n",
      "904611014 | 905421430 |               PO Box |               PO Box | 1.000 | 1978-10-10\n",
      "904611014 | 905921759 |               PO Box |               PO Bax | 0.889 | 1978-12-07\n",
      "904701062 | 904701063 |                WAYST |                WAYST | 1.000 | 1978-06-24\n",
      "904831137 | 904831138 |         tandard Stre |         tandard Stre | 1.000 | 1978-07-10\n",
      "904891175 | 904891176 |    imported shoes at |    imported shoes at | 1.000 | 1978-07-15\n",
      "905041238 | 905041239 |          The citiznr |          The citiznr | 1.000 | 1978-08-18\n",
      "905041241 | 905231328 |         Birindy Sibo |     Birindwa Sibocha | 0.868 | 1978-09-18\n",
      "905051245 | 905051250 |  human dignity asADS |     human dignity DS | 0.947 | 1978-08-24\n",
      "905221321 | 905221322 |          Reuben Otte |          Reuben Otte | 1.000 | 1978-09-16\n",
      "905271349 | 905301365 |          ON VERY EAS |          ONVERY EASY | 0.856 | 1978-09-26\n",
      "905271349 | 905561518 |          ON VERY EAS |         ON VERY EASY | 0.972 | 1978-10-26\n",
      "905421436 | 905891744 |            Please he |               Please | 0.889 | 1978-12-04\n",
      "905601542 | 905601544 |                sneci |                sneci | 1.000 | 1978-10-31\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "prj_root = os.path.dirname(current_directory)\n",
    "data_dir = f'{prj_root}/data'\n",
    "bylines_and_files_dir = f'{data_dir}/bylines_and_files'\n",
    "\n",
    "proc_year = \"1978\"\n",
    "\n",
    "data = pd.read_csv(f'{bylines_and_files_dir}/{proc_year}.tsv', \n",
    "                   delimiter='\\t', \n",
    "                   usecols=['reader_name', 'reader_location', 'reader_title', 'reader_org', 'txt_name', 'letter_date', 'lines_count'],\n",
    "                   na_filter=False\n",
    "                  )\n",
    "min_length = 5 # min length of valid string to compare\n",
    "\n",
    "edges_list = []\n",
    "nodes_list = []\n",
    "skip_list = []\n",
    "for i, irow in data.iterrows():\n",
    "    ireader_name = irow['reader_name']\n",
    "    ireader_location = irow['reader_location']\n",
    "    iletter_date = irow['letter_date']\n",
    "    itxt_name = irow['txt_name']\n",
    "    \n",
    "    if i not in skip_list:  # if sth is already match with high percentage then don't match it sth else    \n",
    "        subj_len = len(ireader_name)\n",
    "        # generate a unique id for the record on the whole corpora\n",
    "        uid = f'{itxt_name[4:9]}{i:>04}'\n",
    "    \n",
    "        if subj_len > min_length:  # consider valid strings only\n",
    "\n",
    "            subject_name = cleanup_name(ireader_name)\n",
    "            subject_name = str(subject_name)\n",
    "            ignore_these = [] # list of matches to ignore same page letters\n",
    "            for j, jrow in data.iloc[i+1:].iterrows(): # inner loop begins after subject to avoid duplications\n",
    "                jreader_name = jrow['reader_name']\n",
    "                jtxt_name = jrow['txt_name']\n",
    "                jletter_date = jrow['letter_date']\n",
    "                \n",
    "                comp_len = len(jreader_name)\n",
    "\n",
    "                # again, consider valid strings only\n",
    "                # also not too long than the subject name\n",
    "                if comp_len > min_length:\n",
    "                    comp_name = cleanup_name(jreader_name)\n",
    "                    comp_name = str(comp_name)\n",
    "                    sim_val = jellyfish.jaro_distance(subject_name, comp_name)\n",
    "\n",
    "                    if sim_val >= 0.84:\n",
    "                        ujd = f'{jtxt_name[4:9]}{j:>04}'\n",
    "                        foundlings = [x for x in ignore_these if x.startswith(jtxt_name[:10])]\n",
    "                        if len(foundlings) > 0:\n",
    "                            # because this letter is from same page and not possible to have \n",
    "                            # more than one letter from same reader in same column. So skip\n",
    "                            continue\n",
    "                        skip_list.append(j)\n",
    "                        print(f'{uid:>09} | {ujd:>09} | {subject_name:>20} | {comp_name:>20} | {sim_val:.3f} | {jletter_date:>10}')\n",
    "                        \n",
    "                        edges_list.append([ujd, uid, ireader_name, jreader_name, sim_val, jletter_date, jtxt_name])\n",
    "                        \n",
    "                        nodes_list.append([uid, subject_name, ireader_name, iletter_date, itxt_name])\n",
    "                        nodes_list.append([ujd, comp_name, jreader_name, jletter_date, jtxt_name])\n",
    "                        \n",
    "                        ignore_these.append(jtxt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes and edges for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create an edges output\n",
    "edge_headers = ['source', 'target', 'ireader_name', 'jreader_name', 'sim_val', 'jletter_date', 'jtxt_name']\n",
    "sims_df = pd.DataFrame(edges_list, columns=edge_headers)\n",
    "\n",
    "# export to edges.tsv\n",
    "processed_tsv = os.path.join(bylines_and_files_dir, f'{proc_year}_jellyfish_edges.tsv')\n",
    "sims_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = edge_headers)\n",
    "\n",
    "### create an nodes output\n",
    "node_headers = ['id', 'label', 'ireader_name', 'iletter_date', 'itxt_name']\n",
    "nodes_df = pd.DataFrame(nodes_list, columns=node_headers)\n",
    "\n",
    "# dropping ALL duplicte values based on 'id' \n",
    "nodes_df.drop_duplicates(subset =\"id\", keep = 'first', inplace = True)\n",
    "\n",
    "# export to nodes.tsv\n",
    "processed_tsv = os.path.join(bylines_and_files_dir, f'{proc_year}_jellyfish_nodes.tsv')\n",
    "nodes_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = node_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other resources\n",
    "\n",
    "[https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings](https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings)\n",
    "\n",
    "[https://stackoverflow.com/a/55732255/754432](https://stackoverflow.com/a/55732255/754432) (How to draw heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
