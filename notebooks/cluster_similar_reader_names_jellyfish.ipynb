{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byline Similarities of names using [jellyfish](https://github.com/jamesturk/jellyfish)\n",
    "\n",
    "Bylines were extracted from the the last paragraph of each letter. This was done here [Extract bylines from raw letters](/notebooks/extract_letter_bylines.ipynb) where attempts to identify the different sections of byline including name, occupation and location done. This notebook is thus concerned with associating–despite errors in the OCR process–the named identities and number of letters they sent to the editor.\n",
    "\n",
    "Unlike semantic based algorithms such as the one provided by the spaCy nlp library (see [attempt Byline Similarities of names using spaCy](/notebooks/cluster_similar_reader_names_spacy.ipynb)), using jaro distance, one of similarity algorithms provided by jellyfish package performed much better overall and was thus employed in the research.\n",
    "\n",
    "In order maximise the results, `cleanup_name` function ensure noise characters such and other non-alphabeticals were removed altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanup_name(_input):\n",
    "    output = ireader_name = re.sub(r'[^A-Za-z0-9 ]+', '', _input) # strip dots\n",
    "    output = re.sub(r\"\\b[a-zA-Z0-9]\\b\", \"\", output) # remove single letter words\n",
    "    output = re.sub(' +', ' ', output) # remove successive spaces\n",
    "    output = output.strip() # remove leading and trailing spaces\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step helped to make similarities possible where otherwise would not have been established due to the state of the OCR errors. For example in the case below, two byline identities “HM Mwafusi” and “A H..M. Mwafusi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Similarity before clean-up: 0.8388888888888889\n",
      "    Similarity after clean-up: 1.0\n"
     ]
    }
   ],
   "source": [
    "import jellyfish\n",
    "\n",
    "id1 = 'HM Mwafusi'\n",
    "id2 = 'A H..M. Mwafusi'\n",
    "ratio = jellyfish.jaro_distance(id1, id2)\n",
    "print(f\"{'Similarity before clean-up:':>30} {ratio}\")\n",
    "\n",
    "id1 = cleanup_name(id1)\n",
    "id2 = cleanup_name(id2)\n",
    "ratio = jellyfish.jaro_distance(id1, id2)\n",
    "print(f\"{'Similarity after clean-up:':>30} {ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating similarities\n",
    "\n",
    "Two key parameters were used in the determinations. The `min_length` was used to limit valid words and ratio was set to `0.84` where results were reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903250005 | 903250006 |   the resovmed eters | athe resovmed aaters | 0.912 | 1978-01-03\n",
      "903350084 | 905881730 | Tappeal to the Government to do | appeal to the Governme | 0.903 | 1978-12-02\n",
      "903360085 | 903360086 | As far as Gema is concerned we | As far as Gema is concerned we | 1.000 | 1978-01-17\n",
      "903380103 | 904731071 |          FpA Apollos |           FM Apollos | 0.869 | 1978-06-28\n",
      "903400115 | 903880487 |      Wilfred Waititu |    Woailfred Waititu | 0.861 | 1978-03-18\n",
      "903400115 | 903910517 |      Wilfred Waititu |      Wilfred Waititu | 1.000 | 1978-03-22\n",
      "903400115 | 904200720 |      Wilfred Waititu |      Wilfred Waititu | 1.000 | 1978-04-26\n",
      "903440141 | 904731071 |            FM Appoll |           FM Apollos | 0.896 | 1978-06-28\n",
      "903440143 | 903480162 |  ion Mrs KeliNairobi | Ring Mrs KeliNairobi | 0.949 | 1978-01-31\n",
      "903470155 | 903710350 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-02-27\n",
      "903470155 | 903750384 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-03-03\n",
      "903470155 | 903980573 |       Jimmy Mohammed |       Jimmy Mohammed | 1.000 | 1978-03-31\n",
      "903490169 | 903620263 |  Tokyo Charles Waldi |       oy Charles Wal | 0.912 | 1978-02-16\n",
      "903550206 | 903940551 |        Thande Bakana |         hande Bakano | 0.921 | 1978-03-27\n",
      "903590244 | 904060626 | METROPOLITAN COLLEGE DEPTWD | METROPOLITAN COLLEGE DBI | 0.910 | 1978-04-10\n",
      "903630279 | 905241326 |          my Mahammed |          my Mohammed | 0.906 | 1978-09-19\n",
      "903690319 | 903700333 |     Bitindwa Sibocha |     Bitindwa Sibocho | 0.958 | 1978-02-25\n",
      "903690319 | 905231324 |     Bitindwa Sibocha |     Birindwa Sibocha | 0.958 | 1978-09-18\n",
      "903690327 | 903950559 |   Frustrated citizen |           Frustrated | 0.852 | 1978-03-28\n",
      "903690329 | 905701623 |              Mombasa |              Mombasa | 1.000 | 1978-11-11\n",
      "903700334 | 905961780 |           ee Nairobi |              Nairobi | 0.900 | 1978-12-12\n",
      "903700337 | 904731071 |           EM Apolios |           FM Apollos | 0.867 | 1978-06-28\n",
      "903730366 | 903730367 | Kisumu 2630 Mombasa 21251 Malindi | Kisumu 2630 Mombasa 24254 Malina | 0.928 | 1978-03-01\n",
      "903740368 | 903740370 |  In his classic work |  In his classic work | 1.000 | 1978-03-02\n",
      "903740373 | 904200718 |       Gobriel Adulla |       Gobriel Ndullo | 0.905 | 1978-04-26\n",
      "903760388 | 905721632 |                Kenya |              Kenyans | 0.905 | 1978-11-14\n",
      "903840453 | 903860469 |  Uhuru Highway POBox |          Uhuru Highw | 0.860 | 1978-03-16\n",
      "903910515 | 905151268 |         Daudi Luvusi |         Doudi Luvusi | 0.944 | 1978-09-08\n",
      "903910515 | 905281350 |         Daudi Luvusi |         Daudi Lavesi | 0.889 | 1978-09-23\n",
      "903930532 | 905261340 |          Perhaps the |          Perhaps the | 1.000 | 1978-09-21\n",
      "904230743 | 905631572 |  Evans Ernest Luseno |    Evans Ernest send | 0.928 | 1978-11-03\n",
      "904250765 | 904250766 |               esinma |               esinma | 1.000 | 1978-05-02\n",
      "904310799 | 904560979 |   little more and in |  alittle more and in | 0.982 | 1978-06-08\n",
      "904330814 | 904330815 | will be the least result | will be the least result | 1.000 | 1978-05-11\n",
      "904340822 | 904340823 |              Our mot |              Our mot | 1.000 | 1978-05-12\n",
      "904350832 | 904350834 |           he tiidest |           he tiidest | 1.000 | 1978-05-12\n",
      "904360836 | 904360837 |   PRICE YOU CANT AVE |   PRICE YOU CANT AVE | 1.000 | 1978-05-15\n",
      "904390865 | 904390866 | The meeting will be informal and willcommence punctual | The meeting will be informal and willcommence punctual | 1.000 | 1978-05-18\n",
      "904390867 | 904390868 | sesamin Baorcld Memse | sesamin Baorcld Memse | 1.000 | 1978-05-18\n",
      "904400871 | 904611012 |               PO Box |               PO Box | 1.000 | 1978-06-14\n",
      "904400871 | 904951198 |               PO Box |               PO Box | 1.000 | 1978-07-22\n",
      "904400871 | 905421430 |               PO Box |               PO Box | 1.000 | 1978-10-10\n",
      "904400871 | 905921753 |               PO Box |               PO Bax | 0.889 | 1978-12-07\n",
      "904420888 | 904420889 |        Sylvia Fraser |        Sylvia Fraser | 1.000 | 1978-05-22\n",
      "904510948 | 904831129 |              RAIROBI |              NAIROBI | 0.905 | 1978-07-10\n",
      "904701057 | 904701058 |                WAYST |                WAYST | 1.000 | 1978-06-24\n",
      "904831131 | 904831132 |         tandard Stre |         tandard Stre | 1.000 | 1978-07-10\n",
      "904891170 | 904891171 |    imported shoes at |    imported shoes at | 1.000 | 1978-07-15\n",
      "904921182 | 904921183 |               ywinoe |               ywinoe | 1.000 | 1978-07-19\n",
      "905001217 | 905001219 |        eye see ee ee |        eye see ee ee | 1.000 | 1978-07-28\n",
      "905041231 | 905231324 |         Birindy Sibo |     Birindwa Sibocha | 0.868 | 1978-09-18\n",
      "905041234 | 905041235 |          The citiznr |          The citiznr | 1.000 | 1978-08-18\n",
      "905051238 | 905051239 |     human dignity DS |  human dignity asADS | 0.947 | 1978-08-24\n",
      "905191291 | 905641582 |       Williom Okello |       William Okello | 0.952 | 1978-11-04\n",
      "905221320 | 905221321 |          Reuben Otte |          Reuben Otte | 1.000 | 1978-09-16\n",
      "905421428 | 905891732 |            Please he |               Please | 0.889 | 1978-12-04\n",
      "905601543 | 905601545 |                sneci |                sneci | 1.000 | 1978-10-31\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "prj_root = os.path.dirname(current_directory)\n",
    "data_dir = f'{prj_root}/data'\n",
    "bylines_and_files_dir = f'{data_dir}/bylines_and_files'\n",
    "\n",
    "proc_year = \"1978\"\n",
    "\n",
    "data = pd.read_csv(f'{bylines_and_files_dir}/{proc_year}.tsv', \n",
    "                   delimiter='\\t', \n",
    "                   usecols=['reader_name', 'reader_location', 'reader_title', 'reader_org', 'txt_name', 'letter_date', 'lines_count'],\n",
    "                   na_filter=False\n",
    "                  )\n",
    "min_length = 5 # min length of valid string to compare\n",
    "\n",
    "edges_list = []\n",
    "nodes_list = []\n",
    "skip_list = []\n",
    "for i, irow in data.iterrows():\n",
    "    ireader_name = irow['reader_name']\n",
    "    ireader_location = irow['reader_location']\n",
    "    iletter_date = irow['letter_date']\n",
    "    itxt_name = irow['txt_name']\n",
    "    \n",
    "    if i not in skip_list:  # if sth is already match with high percentage then don't match it sth else    \n",
    "        subj_len = len(ireader_name)\n",
    "        # generate a unique id for the record on the whole corpora\n",
    "        uid = f'{itxt_name[4:9]}{i:>04}'\n",
    "    \n",
    "        if subj_len > min_length:  # consider valid strings only\n",
    "\n",
    "            subject_name = cleanup_name(ireader_name)\n",
    "            subject_name = str(subject_name)\n",
    "            ignore_these = [] # list of matches to ignore same page letters\n",
    "            for j, jrow in data.iloc[i+1:].iterrows(): # inner loop begins after subject to avoid duplications\n",
    "                jreader_name = jrow['reader_name']\n",
    "                jtxt_name = jrow['txt_name']\n",
    "                jletter_date = jrow['letter_date']\n",
    "                \n",
    "                comp_len = len(jreader_name)\n",
    "\n",
    "                # again, consider valid strings only\n",
    "                # also not too long than the subject name\n",
    "                if comp_len > min_length:\n",
    "                    comp_name = cleanup_name(jreader_name)\n",
    "                    comp_name = str(comp_name)\n",
    "                    sim_val = jellyfish.jaro_distance(subject_name, comp_name)\n",
    "\n",
    "                    if sim_val >= 0.84:\n",
    "                        ujd = f'{jtxt_name[4:9]}{j:>04}'\n",
    "                        foundlings = [x for x in ignore_these if x.startswith(jtxt_name[:10])]\n",
    "                        if len(foundlings) > 0:\n",
    "                            # because this letter is from same page and not possible to have \n",
    "                            # more than one letter from same reader in same column. So skip\n",
    "                            continue\n",
    "                        skip_list.append(j)\n",
    "                        print(f'{uid:>09} | {ujd:>09} | {subject_name:>20} | {comp_name:>20} | {sim_val:.3f} | {jletter_date:>10}')\n",
    "                        \n",
    "                        edges_list.append([ujd, uid, ireader_name, jreader_name, sim_val, jletter_date, jtxt_name])\n",
    "                        \n",
    "                        nodes_list.append([uid, subject_name, ireader_name, iletter_date, itxt_name])\n",
    "                        nodes_list.append([ujd, comp_name, jreader_name, jletter_date, jtxt_name])\n",
    "                        \n",
    "                        ignore_these.append(jtxt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes and edges for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create an edges output\n",
    "edge_headers = ['source', 'target', 'ireader_name', 'jreader_name', 'sim_val', 'jletter_date', 'jtxt_name']\n",
    "sims_df = pd.DataFrame(edges_list, columns=edge_headers)\n",
    "\n",
    "# export to edges.tsv\n",
    "processed_tsv = os.path.join(bylines_and_files_dir, f'{proc_year}_jellyfish_edges.tsv')\n",
    "sims_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = edge_headers)\n",
    "\n",
    "### create an nodes output\n",
    "node_headers = ['id', 'label', 'ireader_name', 'iletter_date', 'itxt_name']\n",
    "nodes_df = pd.DataFrame(nodes_list, columns=node_headers)\n",
    "\n",
    "# dropping ALL duplicte values based on 'id' \n",
    "nodes_df.drop_duplicates(subset =\"id\", keep = 'first', inplace = True)\n",
    "\n",
    "# export to nodes.tsv\n",
    "processed_tsv = os.path.join(bylines_and_files_dir, f'{proc_year}_jellyfish_nodes.tsv')\n",
    "nodes_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = node_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other resources\n",
    "\n",
    "[https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings](https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings)\n",
    "\n",
    "[https://stackoverflow.com/a/55732255/754432](https://stackoverflow.com/a/55732255/754432) (How to draw heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
