{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bylines from OCR letters\n",
    "\n",
    "1. Loop through a directory letters. Extracted by year.\n",
    "* Parse each letter simply to extract the last occuring sentences before an empty line.\n",
    "* Create a tsv file with extracted byline and file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files extract in 1978 columns are: 4424\n",
      "\n",
      "[ 'dds-90325-page-8-article-01.txt',\n",
      "  'dds-90325-page-8-article-03.txt',\n",
      "  'dds-90325-page-8-article-05.txt',\n",
      "  'dds-90325-page-8-article-06.txt',\n",
      "  'dds-90325-page-8-article-08.txt',\n",
      "  'dds-90325-page-8-article-10.txt',\n",
      "  'dds-90325-page-8-article-12.txt',\n",
      "  'dds-90325-page-8-article-13.txt',\n",
      "  'dds-90325-page-8-article-14.txt',\n",
      "  'dds-90325-page-8-article-15.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "prj_root = os.path.dirname(current_directory)\n",
    "data_dir = f'{prj_root}/data'\n",
    "txt_xml_dir = f'{prj_root}/data/TXT_XML'\n",
    "\n",
    "proc_year = \"1978\"\n",
    "path_list = []\n",
    "for f in sorted(Path(txt_xml_dir).glob(f'{proc_year}/*.txt')):\n",
    "    txt_path = str(f) # cast PosixPath to str\n",
    "    txt_name = os.path.basename(txt_path)\n",
    "    path_list.append(txt_name)\n",
    "\n",
    "print(f\"Total files extract in {proc_year} columns are: {len(path_list)}\\n\")\n",
    "pprint(path_list[0:10], indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of titles\n",
    "\n",
    "**Extract the first 'paragraph' in a text file.** Since the OCR output separated the title from the body text using an empty line in the extract texts, this characteristic was used to retrieve titles.\n",
    "\n",
    "#### Split the byline depending on length\n",
    "1. If the byline has one line. Split the byline into two using the last comma character. The first section being the name and the following section as location.\n",
    "* If three. The first line is name/title. The second is company/organization and the third is location.\n",
    "* If four. The first line is name. The second is title/position. The third is company/organization and the fourth is location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_byline(byline_list):\n",
    "    lines = len(byline_list)\n",
    "    reader_name = ''\n",
    "    reader_title = ''\n",
    "    reader_org = ''\n",
    "    reader_location = ''\n",
    "    \n",
    "    if lines == 1:\n",
    "        stripped_byline = byline_list[0].rstrip('\\,') # strip any ending commas\n",
    "        byline = stripped_byline.rpartition(',')\n",
    "        reader_name = byline[0]\n",
    "        reader_location = byline[1]\n",
    "    elif lines == 2:\n",
    "        reader_name = byline_list[0]\n",
    "        reader_location = byline_list[1]\n",
    "    elif lines == 3:\n",
    "        reader_name = byline_list[0]\n",
    "        reader_title = byline_list[1]\n",
    "        reader_location = byline_list[2]\n",
    "    elif lines == 4:\n",
    "        reader_name = byline_list[0]\n",
    "        reader_title = byline_list[1]\n",
    "        reader_org = byline_list[2]        \n",
    "        reader_location = byline_list[3] \n",
    "    \n",
    "    return reader_name, reader_location, reader_title, reader_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ['', '', '', '', 'dds-90330-page-8-article-21.txt', 1],\n",
      "  ['', '', '', '', 'dds-90331-page-8-article-01.txt', 1],\n",
      "  ['a', 'jot', '', '', 'dds-90331-page-8-article-14.txt', 2],\n",
      "  [ 'HAND IT “TO YOu, MATE',\n",
      "    'LIKE YOU CAN',\n",
      "    '—— NONE OF US CANGET THE GIRLS',\n",
      "    '',\n",
      "    'dds-90331-page-8-article-17.txt',\n",
      "    3],\n",
      "  ['', '', '', '', 'dds-90331-page-8-article-21.txt', 1],\n",
      "  ['egal', 'with', '', '', 'dds-90331-page-8-article-25.txt', 2],\n",
      "  ['', '', '', '', 'dds-90331-page-8-article-29.txt', 1],\n",
      "  ['', '', '', '', 'dds-90332-page-8-article-04.txt', 1],\n",
      "  [ 'SESTT SCS Ua',\n",
      "    'REE RA ake',\n",
      "    '£5 3',\n",
      "    '',\n",
      "    'dds-90332-page-8-article-09.txt',\n",
      "    3],\n",
      "  ['', '', '', '', 'dds-90332-page-8-article-14.txt', 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bylines_and_files_dir = f'{data_dir}/bylines_and_files'\n",
    "\n",
    "if not os.path.exists(bylines_and_files_dir):\n",
    "    os.makedirs(bylines_and_files_dir)\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text)\n",
    "# def words(text): return re.findall(r'[^-,\\.\\n\\r\\s]+', text, flags=re.ASCII) # [^,\\s]+ match any text that is not a tab and not a whitespace.\n",
    "\n",
    "valid_files = 0\n",
    "bylines_list = []\n",
    "for idx, path in enumerate(path_list):\n",
    "    # print(f'------++++++++++++==================== BEGIN {path} ================++++++++++------')\n",
    "    txt_name = os.path.basename(path)\n",
    "    txt_sans_ext = os.path.splitext(txt_name)[0]\n",
    "    txt_path = f\"{txt_xml_dir}/{proc_year}/{path}\"\n",
    "    \n",
    "    # only handle non-empty files\n",
    "    if os.stat(txt_path).st_size >= 20: # more 20 bytes at least\n",
    "        valid_files += 1\n",
    "        with open(txt_path, 'r', encoding='utf-8') as infile:\n",
    "            file_lines = infile.readlines()\n",
    "            last_pos = 0\n",
    "            try:\n",
    "                # to get last element occurrence of paragraph \n",
    "                last_pos = max(idx for idx, aline in enumerate(file_lines)  \n",
    "                                                    if aline == '\\n')\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "            \n",
    "            byline_section = file_lines[last_pos+1:]\n",
    "            if last_pos > 0 and len(byline_section) <= 3:  # position found\n",
    "                byline_fragments = []\n",
    "                \n",
    "                byline_section = [x.strip() for x in byline_section]\n",
    "                reader_name, reader_location, reader_title, reader_org = proc_byline(byline_section)\n",
    "                reader_name = re.sub('^[^a-zA-Z]*|[^a-zA-Z]*$','',reader_name)\n",
    "                bylines_list.append([reader_name, reader_location, reader_title, reader_org, txt_name, len(byline_section)])\n",
    "            else: # means it was never set due to error caught above\n",
    "                pass\n",
    "\n",
    "pprint(bylines_list[50:60], indent=2)\n",
    "\n",
    "titles_headers = ['reader_name', 'reader_location', 'reader_title', 'reader_org', 'txt_name', 'lines_count']\n",
    "titles_df = pd.DataFrame(bylines_list, columns=titles_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign dates to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "column_dates_df = pd.read_csv(f'{data_dir}/column_dates/{proc_year}.tsv', \n",
    "                   delimiter='\\t', \n",
    "                   usecols=['page_image_name', 'cleaned_date'],\n",
    "                   na_filter=False\n",
    "                  )\n",
    "\n",
    "bylines_list_with_dates = []\n",
    "for index, row in titles_df.iterrows():\n",
    "    reader_name = row['reader_name']\n",
    "    reader_location = row['reader_location']\n",
    "    reader_title = row['reader_title']\n",
    "    reader_org = row['reader_org']\n",
    "    txt_name = row['txt_name']\n",
    "    lines_count = row['lines_count']\n",
    "\n",
    "    for jndex, row in column_dates_df.iterrows():\n",
    "        page_image_name = row['page_image_name']\n",
    "        cleaned_date = row['cleaned_date']\n",
    "        cleaned_datetime_obj = datetime.strptime(cleaned_date , '%Y-%m-%d')    \n",
    "\n",
    "        if txt_name.startswith(page_image_name):\n",
    "            # know the date of the file\n",
    "            bylines_list_with_dates.append([\n",
    "                reader_name, \n",
    "                reader_location, \n",
    "                reader_title, \n",
    "                reader_org, \n",
    "                txt_name, \n",
    "                cleaned_date,\n",
    "                lines_count\n",
    "            ])\n",
    "\n",
    "# updated titles headers and df with known date of column\n",
    "titles_headers = [\n",
    "    'reader_name', \n",
    "    'reader_location', \n",
    "    'reader_title', \n",
    "    'reader_org', \n",
    "    'txt_name', \n",
    "    'letter_date', \n",
    "    'lines_count'\n",
    "]\n",
    "titles_df = pd.DataFrame(bylines_list_with_dates, columns=titles_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now write to file with dates noted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reader_name</th>\n",
       "      <th>reader_location</th>\n",
       "      <th>reader_title</th>\n",
       "      <th>reader_org</th>\n",
       "      <th>txt_name</th>\n",
       "      <th>letter_date</th>\n",
       "      <th>lines_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dds-90325-page-8-article-03.txt</td>\n",
       "      <td>1978-01-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dds-90325-page-8-article-06.txt</td>\n",
       "      <td>1978-01-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dds-90325-page-8-article-10.txt</td>\n",
       "      <td>1978-01-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>institutions: ( ~ os</td>\n",
       "      <td>Kisumu</td>\n",
       "      <td>2° F.R.O. Akubs Koyugy,</td>\n",
       "      <td></td>\n",
       "      <td>dds-90325-page-8-article-12.txt</td>\n",
       "      <td>1978-01-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dds-90325-page-8-article-13.txt</td>\n",
       "      <td>1978-01-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reader_name reader_location             reader_title reader_org  \\\n",
       "0                                                                             \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3  institutions: ( ~ os          Kisumu  2° F.R.O. Akubs Koyugy,              \n",
       "4                                                                             \n",
       "\n",
       "                          txt_name letter_date  lines_count  \n",
       "0  dds-90325-page-8-article-03.txt  1978-01-03            1  \n",
       "1  dds-90325-page-8-article-06.txt  1978-01-03            1  \n",
       "2  dds-90325-page-8-article-10.txt  1978-01-03            1  \n",
       "3  dds-90325-page-8-article-12.txt  1978-01-03            3  \n",
       "4  dds-90325-page-8-article-13.txt  1978-01-03            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to tsv\n",
    "processed_tsv = os.path.join(bylines_and_files_dir, f'{proc_year}.tsv')\n",
    "titles_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = titles_headers)\n",
    "\n",
    "titles_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
