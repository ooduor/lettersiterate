{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract titles from raw letters\n",
    "\n",
    "1. Loop through a directory letters. Extracted by year.\n",
    "* Parse each letter simply to extract the first occuring sentences before an empty line.\n",
    "* Create a tsv file with extracted title and file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files extract in 1977 columns are: 4838\n",
      "\n",
      "[ 'dds-90009-page-8-article-01.txt',\n",
      "  'dds-90009-page-8-article-02.txt',\n",
      "  'dds-90009-page-8-article-03.txt',\n",
      "  'dds-90009-page-8-article-05.txt',\n",
      "  'dds-90009-page-8-article-06.txt',\n",
      "  'dds-90010-page-8-article-01.txt',\n",
      "  'dds-90010-page-8-article-03.txt',\n",
      "  'dds-90010-page-8-article-05.txt',\n",
      "  'dds-90010-page-8-article-08.txt',\n",
      "  'dds-90010-page-8-article-10.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "prj_root = os.path.dirname(current_directory)\n",
    "data_dir = f'{prj_root}/data'\n",
    "txt_dir = f'{prj_root}/data/TXT_XML'\n",
    "training_letters_dir = f'{prj_root}/data/training/letters'\n",
    "\n",
    "proc_year = \"1978\"\n",
    "path_list = []\n",
    "for f in sorted(Path(txt_dir).glob(f'{proc_year}/*.txt')):\n",
    "    txt_path = str(f) # cast PosixPath to str\n",
    "    txt_name = os.path.basename(txt_path)\n",
    "    path_list.append(txt_name)\n",
    "\n",
    "print(f\"Total files extract in {proc_year} columns are: {len(path_list)}\\n\")\n",
    "pprint(path_list[0:10], indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of titles\n",
    "\n",
    "**Extract the first 'paragraph' in a text file.** Since the OCR output separated the title from the body text using an empty line in the extract texts, this characteristic was used to retrieve titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid files found: 3935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>txt_name</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wiolence in Southern Africa —</td>\n",
       "      <td>dds-90009-page-8-article-01.txt</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>An end to non violence</td>\n",
       "      <td>dds-90009-page-8-article-02.txt</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The war of the ape and the fish</td>\n",
       "      <td>dds-90009-page-8-article-03.txt</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The power struggle in China</td>\n",
       "      <td>dds-90009-page-8-article-05.txt</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Let the people decide</td>\n",
       "      <td>dds-90009-page-8-article-06.txt</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Harassing wananchi</td>\n",
       "      <td>dds-90010-page-8-article-01.txt</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>MERU KANU ELECTIONS WERE UNFAIR AND UNDEMOCRATIC</td>\n",
       "      <td>dds-90010-page-8-article-05.txt</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Eliminate comuption</td>\n",
       "      <td>dds-90010-page-8-article-08.txt</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Excellent bank services</td>\n",
       "      <td>dds-90010-page-8-article-10.txt</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ABOLISH CHRISTMAS HOLIDAY BECAUSE IT’S UNPRODU...</td>\n",
       "      <td>dds-90010-page-8-article-12.txt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                      Wiolence in Southern Africa —   \n",
       "1                             An end to non violence   \n",
       "2                    The war of the ape and the fish   \n",
       "3                        The power struggle in China   \n",
       "4                              Let the people decide   \n",
       "5                                 Harassing wananchi   \n",
       "6   MERU KANU ELECTIONS WERE UNFAIR AND UNDEMOCRATIC   \n",
       "7                                Eliminate comuption   \n",
       "8                            Excellent bank services   \n",
       "9  ABOLISH CHRISTMAS HOLIDAY BECAUSE IT’S UNPRODU...   \n",
       "\n",
       "                          txt_name  title_length  \n",
       "0  dds-90009-page-8-article-01.txt            31  \n",
       "1  dds-90009-page-8-article-02.txt            23  \n",
       "2  dds-90009-page-8-article-03.txt            32  \n",
       "3  dds-90009-page-8-article-05.txt            28  \n",
       "4  dds-90009-page-8-article-06.txt            22  \n",
       "5  dds-90010-page-8-article-01.txt            19  \n",
       "6  dds-90010-page-8-article-05.txt            49  \n",
       "7  dds-90010-page-8-article-08.txt            20  \n",
       "8  dds-90010-page-8-article-10.txt            24  \n",
       "9  dds-90010-page-8-article-12.txt            52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles_and_files_dir = f'{data_dir}/titles_and_files'\n",
    "\n",
    "if not os.path.exists(titles_and_files_dir):\n",
    "    os.makedirs(titles_and_files_dir)\n",
    "\n",
    "# def words(text): return re.findall(r'\\w+', text)\n",
    "def words(text): return re.findall(r'[^-,\\.\\n\\r\\s]+', text, flags=re.ASCII) # [^,\\s]+ match any text that is not a tab and not a whitespace.\n",
    "\n",
    "valid_files = 0\n",
    "titles_list = []\n",
    "for idx, path in enumerate(path_list):\n",
    "    # print(f'------++++++++++++==================== BEGIN {path} ================++++++++++------')\n",
    "    txt_name = os.path.basename(path)\n",
    "    txt_sans_ext = os.path.splitext(txt_name)[0]\n",
    "    txt_path = f\"{txt_dir}/{proc_year}/{path}\"\n",
    "    \n",
    "    # only handle non-empty files\n",
    "    if os.stat(txt_path).st_size >= 20: # more 20 bytes at least\n",
    "        valid_files += 1\n",
    "        with open(txt_path, 'r', encoding='utf-8') as infile:\n",
    "            file_lines = infile.readlines()\n",
    "            title_fragments = []\n",
    "            for j, line in enumerate(file_lines):\n",
    "                # 1) first 'paragraph' in a letter\n",
    "                if line == '\\n':\n",
    "                    title_length = file_lines[:j]\n",
    "                    # check that it is not a paragraph masquerading as a tile\n",
    "                    if sum([len(x) for x in title_length]) < 100:\n",
    "                        # get all the previous lines... \n",
    "                        title_fragments = title_length\n",
    "\n",
    "                    # exit this loop, regardless\n",
    "                    break\n",
    "                \n",
    "                # 2) if we get to last line without any fragment \n",
    "                # i.e found only one 'paragraph' in the extract file then \n",
    "                # check that the last line is not too long and get everything as title\n",
    "                if len(file_lines) == j+1 and sum([len(x) for x in file_lines]) <= 100:\n",
    "                    title_fragments = file_lines\n",
    "                    \n",
    "            if len(title_fragments) > 0:\n",
    "                title = ' '.join(title_fragments)  # join them with white space xter\n",
    "                title = words(title)  # clean up title\n",
    "                title = ' '.join(title)\n",
    "                titles_list.append([title, txt_name, sum([len(x) for x in title_length])])               \n",
    "\n",
    "headers = ['title', 'txt_name', 'title_length']\n",
    "titles_df = pd.DataFrame(titles_list, columns=headers)\n",
    "\n",
    "# export to tsv\n",
    "processed_tsv = os.path.join(titles_and_files_dir, f'{proc_year}.tsv')\n",
    "titles_df.to_csv(processed_tsv, \n",
    "                sep='\\t',\n",
    "                encoding='utf-8', \n",
    "                index=False,\n",
    "                columns = headers)\n",
    "                \n",
    "print(f\"Valid files found: {valid_files}\")\n",
    "titles_df.head(10)\n",
    "# pprint(titles_list[0:1000], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
